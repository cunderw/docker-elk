filebeat.inputs:
- type: container
  combine_partial: true
  paths: "/usr/share/filebeat/dockerlogs/*/*.log"
  exclude_files: ['\.gz$']

filebeat.modules:
- module: nginx
  access:
    enabled: true
    var.paths: ["/usr/share/filebeat/nginx/access.log"]    
  error:
    enabled: true
    var.paths: ["/usr/share/filebeat/nginx/error.log"]

- module: system
  syslog:
    enabled: true
    var.paths: ["/usr/share/filebeat/log/syslog"]
  #auth:
  # enabled: true
    #var.paths: ["/var/log/syslog"]

processors:
  # decode the log field (sub JSON document) if JSON encoded, then maps it's fields to elasticsearch fields
- decode_json_fields:
    fields: ["log", "message"]
    target: ""
    # overwrite existing target elasticsearch fields while decoding json fields    
    overwrite_keys: true
- add_docker_metadata:
    host: "unix:///var/run/docker.sock"
    match_fields: ["system.process.cgroup.id"]
    match_pids: ["process.pid", "process.ppid"]
    match_source: true
    match_source_index: 4
    match_short_id: false
    cleanup_timeout: 60
    labels.dedot: false

filebeat.config.modules:
  path: /usr/share/filebeat/modules.d/*.yml 
  reload.enabled: true

# setup filebeat to send output to logstash
output.logstash:
  enabled: true 
  hosts: ["10.1.0.254:5044"]
setup.kibana:
  host: "10.1.0.254:5601"
